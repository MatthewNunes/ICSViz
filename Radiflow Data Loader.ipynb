{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "biblical-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "import pickle\n",
    "\n",
    "##local python file holding the paths to the directories I store the log files in\n",
    "from directories_to_use import argus_text_files_dir, getTestingDir, getRadiflowNormal, getRadiflowAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "still-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read Argus text files into one single dataframe\n",
    "\"\"\"\n",
    "def readDataIntoDataframe(argus_text_files_dir):\n",
    "    first_time = True\n",
    "    for t_file in os.listdir(argus_text_files_dir):\n",
    "        #print(t_file)\n",
    "        if first_time:\n",
    "            new_df = pd.read_csv(argus_text_files_dir + t_file)\n",
    "            date = removeDateFromName(t_file)\n",
    "            new_df[\"StartTime\"] = new_df[\"StartTime\"].apply(lambda x : date + x)\n",
    "            new_df[\"LastTime\"] = new_df[\"LastTime\"].apply(lambda x : date + x)\n",
    "            first_time = False\n",
    "        else:\n",
    "            temp_df = pd.read_csv(argus_text_files_dir + t_file)\n",
    "            date = removeDateFromName(t_file)\n",
    "            temp_df[\"StartTime\"] = temp_df[\"StartTime\"].apply(lambda x : date + x)\n",
    "            temp_df[\"LastTime\"] = temp_df[\"LastTime\"].apply(lambda x : date + x)\n",
    "            new_df = pd.concat([new_df, temp_df], ignore_index=True)\n",
    "    return new_df\n",
    "\n",
    "def removeDateFromName(filename):\n",
    "    year = filename.split(\"_\")[-1][0:4]\n",
    "    month = filename.split(\"_\")[-1][4:6]\n",
    "    day = filename.split(\"_\")[-1][6:8]\n",
    "    full_date = day +\"-\"+ month +\"-\"+ year + \" \"\n",
    "    return full_date\n",
    "\n",
    "#data2017_df = readDataIntoDataframe(argus_text_files_dir)\n",
    "#print(data2017_df.shape)\n",
    "\n",
    "data_radiflow_normal_df = readDataIntoDataframe(getRadiflowNormal())\n",
    "data_radiflow_attack_df = readDataIntoDataframe(getRadiflowAttack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "technical-sight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (31253, 118)\n",
      "Shape after:  (31253, 73)\n",
      "Columns with only Nans: ['SrcMac', 'DstMac', 'SrcOui', 'DstOui', 'sCo', 'dCo', 'sMpls', 'dMpls', 'sAS', 'dAS', 'iAS', 'NStrok', 'sNStrok', 'dNStrok', 'SIntPkt', 'SIntDist', 'SIntPktAct', 'SIntActDist', 'SIntPktIdl', 'SIntIdlDist', 'DIntPkt', 'DIntDist', 'DIntPktAct', 'DIntActDist', 'DIntPktIdl', 'DIntIdlDist', 'SrcJitter', 'SrcJitAct', 'DstJitter', 'DstJitAct', 'Label', 'srcUdata', 'dstUdata', 'sVpri', 'dVpri', 'SRange', 'ERange', 'Inode', 'sPktSz', 'sMaxPktSz', 'dPktSz', 'dMaxPktSz', 'sMinPktSz', 'dMinPktSz', 'dMinPktSz.1']\n",
      "Shape before:  (31253, 73)\n",
      "Shape after:  (31253, 61)\n",
      "Columns with only one unique value: ['Trans', 'IdleTime', 'StdDev', 'AutoId', 'TotAppByte', 'SAppBytes', 'DAppBytes', 'PCRatio', 'Retrans', 'SrcRetra', 'DstRetra', 'pRetran']\n",
      "Shape before:  (10328, 118)\n",
      "Shape after:  (10328, 74)\n",
      "Columns with only Nans: ['SrcMac', 'DstMac', 'SrcOui', 'DstOui', 'sCo', 'dCo', 'sMpls', 'dMpls', 'sAS', 'dAS', 'iAS', 'NStrok', 'sNStrok', 'dNStrok', 'SIntPkt', 'SIntDist', 'SIntPktAct', 'SIntActDist', 'SIntPktIdl', 'SIntIdlDist', 'DIntPkt', 'DIntDist', 'DIntPktAct', 'DIntActDist', 'DIntPktIdl', 'DIntIdlDist', 'SrcJitter', 'SrcJitAct', 'DstJitter', 'DstJitAct', 'Label', 'srcUdata', 'dstUdata', 'sVpri', 'dVpri', 'SRange', 'ERange', 'sPktSz', 'sMaxPktSz', 'dPktSz', 'dMaxPktSz', 'sMinPktSz', 'dMinPktSz', 'dMinPktSz.1']\n",
      "Shape before:  (10328, 74)\n",
      "Shape after:  (10328, 63)\n",
      "Columns with only one unique value: ['Trans', 'StdDev', 'AutoId', 'TotAppByte', 'SAppBytes', 'DAppBytes', 'PCRatio', 'Retrans', 'SrcRetra', 'DstRetra', 'pRetran']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loops through all the columns in the dataframe and removes any that only contain nans\n",
    "\"\"\"\n",
    "def removeNanColumns(dataframe):\n",
    "    print(\"Shape before: \", dataframe.shape)\n",
    "    columns_removed = []\n",
    "    for col in dataframe:\n",
    "        unique_vals = dataframe[col].unique()\n",
    "        if unique_vals.shape[0] == 1:\n",
    "            if np.isnan(unique_vals[0]):\n",
    "                dataframe = dataframe.drop([col], axis=1)\n",
    "                columns_removed.append(col)\n",
    "    print(\"Shape after: \", dataframe.shape)\n",
    "    print(\"Columns with only Nans: \" + str(columns_removed))\n",
    "    return dataframe\n",
    "\n",
    "\"\"\"\n",
    "Remove columns that only contain one unique value.\n",
    "\"\"\"\n",
    "def removeSingleColumns(dataframe):\n",
    "    print(\"Shape before: \", dataframe.shape)\n",
    "    columns_removed = []\n",
    "    for col in dataframe:\n",
    "        unique_vals = dataframe[col].unique()\n",
    "        if unique_vals.shape[0] == 1:\n",
    "            dataframe = dataframe.drop([col], axis=1)\n",
    "            columns_removed.append(col)\n",
    "    print(\"Shape after: \", dataframe.shape)\n",
    "    print(\"Columns with only one unique value: \" + str(columns_removed))\n",
    "    return dataframe\n",
    "\"\"\"\n",
    "Prints the columns in a dataframe and all its unique values\n",
    "\"\"\"\n",
    "def printColumnsAndUniqueVals(dataframe):\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    for col in dataframe.columns:\n",
    "        printmd(\"**\" + col + \"**: \" + str(dataframe[col].unique()))\n",
    "        \n",
    "\"\"\"\n",
    "Basically prints in markdown form, can also render HTML\n",
    "\"\"\"\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "\n",
    "data_radiflow_normal_df = removeNanColumns(data_radiflow_normal_df)\n",
    "data_radiflow_normal_df = removeSingleColumns(data_radiflow_normal_df)\n",
    "data_radiflow_attack_df = removeNanColumns(data_radiflow_attack_df)\n",
    "data_radiflow_attack_df = removeSingleColumns(data_radiflow_attack_df)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "commercial-television",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StartTime     0.0\n",
       "LastTime      0.0\n",
       "Flgs          0.0\n",
       "Dur           0.0\n",
       "RunTime       0.0\n",
       "Mean          0.0\n",
       "Sum           0.0\n",
       "Min           0.0\n",
       "Max           0.0\n",
       "SrcAddr       0.0\n",
       "DstAddr       0.0\n",
       "Proto         0.0\n",
       "Sport         0.0\n",
       "Dport         0.0\n",
       "Cause         0.0\n",
       "TotPkts       0.0\n",
       "SrcPkts       0.0\n",
       "DstPkts       0.0\n",
       "TotBytes      0.0\n",
       "SrcBytes      0.0\n",
       "DstBytes      0.0\n",
       "Load          0.0\n",
       "SrcLoad       0.0\n",
       "DstLoad       0.0\n",
       "Loss          0.0\n",
       "SrcLoss       0.0\n",
       "DstLoss       0.0\n",
       "pLoss         0.0\n",
       "Rate          0.0\n",
       "SrcRate       0.0\n",
       "DstRate       0.0\n",
       "Dir           0.0\n",
       "State         0.0\n",
       "TcpRtt        0.0\n",
       "SynAck        0.0\n",
       "AckDat        0.0\n",
       "Offset        0.0\n",
       "sMeanPktSz    0.0\n",
       "dMeanPktSz    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Print columns and the percentage of nans present in each column\"\"\"\n",
    "pd.options.display.max_rows = 4000\n",
    "data_radiflow_normal_df.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "orange-ultimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24884, 43)\n",
      "(30837, 39)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Drop columns with too many nulls\n",
    "\"\"\"\n",
    "def dropChosenColumns(dataframe, column_names):\n",
    "    for column in column_names:\n",
    "        if column in dataframe:\n",
    "            dataframe = dataframe.drop([column], axis=1)\n",
    "    return dataframe\n",
    "        \n",
    "\"\"\"\n",
    "Replace Nans with 0\n",
    "\"\"\"\n",
    "def replaceNansWithZero(dataframe, column_names):\n",
    "    for column in column_names:\n",
    "        dataframe[column] = dataframe[column].fillna(0)\n",
    "    return dataframe\n",
    "\n",
    "\"\"\"\n",
    "Remove rows with nans for chosen columns\n",
    "\"\"\"\n",
    "def removeNanRows(dataframe, column_names):\n",
    "    for column in column_names:\n",
    "        dataframe = dataframe[dataframe[column].notna()]\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "data_radiflow_normal_rowless = removeNanRows(data_radiflow_normal_df, ['Sport', 'Dport', \"sTtl\"])\n",
    "data_radiflow_normal_rowless = dropChosenColumns(data_radiflow_normal_rowless, [\"TcpOpt\", \"sVid\", \"dVid\", \"Seq\", \"sIpId\", \"dIpId\", \"SrcTCPBase\", \"DstTCPBase\", \"SrcWin\", \"DstWin\", \"dDSb\", \"dTos\", \"dHops\", \"SrcGap\", \"DstGap\", \"dTtl\", \"sVlan\", \"dVlan\"])\n",
    "print(data_radiflow_normal_rowless.shape)\n",
    "\n",
    "\n",
    "\n",
    "data_radiflow_normal_df = dropChosenColumns(data_radiflow_normal_df, [\"TcpOpt\", \"sVid\", \"dVid\", \"Seq\", \"sIpId\", \"dIpId\", \"SrcTCPBase\", \"DstTCPBase\", \"SrcWin\", \"DstWin\", \"sDSb\", \"dDSb\", \"dTos\", \"sTos\", \"dHops\", \"SrcGap\", \"DstGap\", \"sTtl\", \"dTtl\", \"sHops\", \"sVlan\", \"dVlan\"])\n",
    "data_radiflow_normal_df = removeNanRows(data_radiflow_normal_df, ['Sport', 'Dport'])\n",
    "print(data_radiflow_normal_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "legislative-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Needs to know the category e.g. IPs and value to add to the dict of dicts (unique_vals)\n",
    "Returns: the unique int assigned to the value\n",
    "\"\"\"\n",
    "def convertToNum(category, val, unique_vals):\n",
    "    if category not in unique_vals:\n",
    "        unique_vals[category] = {}\n",
    "    if val.strip() not in unique_vals[category].keys():\n",
    "        new_val = len(unique_vals[category].keys())\n",
    "        unique_vals[category][val.strip()] = len(unique_vals[category].keys())\n",
    "        return new_val\n",
    "    else:\n",
    "        return unique_vals[category][val.strip()]\n",
    "    \n",
    "\"\"\"\n",
    "Port numbers are a special case. They're integers stored as strings.\n",
    "They are either hex numbers or standard int strings - therefore, we \n",
    "need to check for hex before casting.\n",
    "\"\"\"  \n",
    "def convertPortToNum(val):\n",
    "    if type(val) == str:\n",
    "        isHex = '0x' in val\n",
    "    elif type(val) == float:\n",
    "        isHex = False\n",
    "    elif type(val) == int:\n",
    "        isHex = False\n",
    "    if isHex:\n",
    "        return int(val, base=16)\n",
    "    else:\n",
    "        return int(val)\n",
    "    \n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Takes a string in the following format:\n",
    "14-06-2017 11:25:58.288831\n",
    "Returns: Timestamp\n",
    "\"\"\"\n",
    "def createTimestamp(datetime_string):\n",
    "    row_date = datetime.strptime(datetime_string, \"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    timestamp = row_date.replace(tzinfo=timezone.utc).timestamp()\n",
    "    return timestamp\n",
    "\n",
    "unique_vals = dict()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "linear-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_radiflow_normal_df[\"Dir\"] = data_radiflow_normal_df[\"Dir\"].apply(lambda x : convertToNum(\"dir\", x, unique_vals))\n",
    "data_radiflow_normal_rowless[\"Dir\"] = data_radiflow_normal_rowless[\"Dir\"].apply(lambda x : convertToNum(\"dir\", x, unique_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "atlantic-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_radiflow_normal_df[\"StartTime\"] = data_radiflow_normal_df[\"StartTime\"].apply(lambda x : createTimestamp(\"24-06-2021 \" + x.split(\".c\")[1].strip()))\n",
    "data_radiflow_normal_df[\"LastTime\"] = data_radiflow_normal_df[\"LastTime\"].apply(lambda x : createTimestamp(\"24-06-2021 \" + x.split(\".c\")[1].strip()))\n",
    "data_radiflow_normal_df[\"SrcAddr\"] = data_radiflow_normal_df[\"SrcAddr\"].apply(lambda x : convertToNum(\"ips\", x, unique_vals))\n",
    "data_radiflow_normal_df[\"DstAddr\"] = data_radiflow_normal_df[\"DstAddr\"].apply(lambda x : convertToNum(\"ips\", x, unique_vals))\n",
    "data_radiflow_normal_df[\"Sport\"] = data_radiflow_normal_df[\"Sport\"].apply(lambda x : convertPortToNum(x))\n",
    "data_radiflow_normal_df[\"Dport\"] = data_radiflow_normal_df[\"Dport\"].apply(lambda x : convertPortToNum(x))\n",
    "\n",
    "data_radiflow_normal_rowless[\"StartTime\"] = data_radiflow_normal_rowless[\"StartTime\"].apply(lambda x : createTimestamp(\"24-06-2021 \" + x.split(\".c\")[1].strip()))\n",
    "data_radiflow_normal_rowless[\"LastTime\"] = data_radiflow_normal_rowless[\"LastTime\"].apply(lambda x : createTimestamp(\"24-06-2021 \" + x.split(\".c\")[1].strip()))\n",
    "data_radiflow_normal_rowless[\"SrcAddr\"] = data_radiflow_normal_rowless[\"SrcAddr\"].apply(lambda x : convertToNum(\"ips\", x, unique_vals))\n",
    "data_radiflow_normal_rowless[\"DstAddr\"] = data_radiflow_normal_rowless[\"DstAddr\"].apply(lambda x : convertToNum(\"ips\", x, unique_vals))\n",
    "data_radiflow_normal_rowless[\"Sport\"] = data_radiflow_normal_rowless[\"Sport\"].apply(lambda x : convertPortToNum(x))\n",
    "data_radiflow_normal_rowless[\"Dport\"] = data_radiflow_normal_rowless[\"Dport\"].apply(lambda x : convertPortToNum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "twelve-venue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10328, 43)\n",
      "(10328, 39)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Takes in two dataframes and makes sure that the columns\n",
    "of test_df are the same as those of train_df. Returns a\n",
    "modified dataframe.\n",
    "\"\"\"\n",
    "def alignToTrainingData(train_df, test_df):\n",
    "    for col in test_df.columns:\n",
    "        if col not in train_df.columns:\n",
    "            test_df = test_df.drop([col], axis=1)\n",
    "    return test_df\n",
    "\n",
    "#data2019_mod_df = data2019_df.copy(deep=True)\n",
    "data_radiflow_attack_rowless = alignToTrainingData(data_radiflow_normal_rowless, data_radiflow_attack_df)\n",
    "print(data_radiflow_attack_rowless.shape)\n",
    "\n",
    "data_radiflow_attack_df = alignToTrainingData(data_radiflow_normal_df, data_radiflow_attack_df)\n",
    "print(data_radiflow_attack_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "amber-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_radiflow_attack_rowless = removeNanRows(data_radiflow_attack_rowless, ['Sport', 'Dport', \"sTtl\"])\n",
    "data_radiflow_attack_df = removeNanRows(data_radiflow_attack_df, ['Sport', 'Dport'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "secret-interval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StartTime     0.0\n",
       "LastTime      0.0\n",
       "Flgs          0.0\n",
       "Dur           0.0\n",
       "RunTime       0.0\n",
       "Mean          0.0\n",
       "Sum           0.0\n",
       "Min           0.0\n",
       "Max           0.0\n",
       "SrcAddr       0.0\n",
       "DstAddr       0.0\n",
       "Proto         0.0\n",
       "Sport         0.0\n",
       "Dport         0.0\n",
       "Cause         0.0\n",
       "TotPkts       0.0\n",
       "SrcPkts       0.0\n",
       "DstPkts       0.0\n",
       "TotBytes      0.0\n",
       "SrcBytes      0.0\n",
       "DstBytes      0.0\n",
       "Load          0.0\n",
       "SrcLoad       0.0\n",
       "DstLoad       0.0\n",
       "Loss          0.0\n",
       "SrcLoss       0.0\n",
       "DstLoss       0.0\n",
       "pLoss         0.0\n",
       "Rate          0.0\n",
       "SrcRate       0.0\n",
       "DstRate       0.0\n",
       "Dir           0.0\n",
       "State         0.0\n",
       "TcpRtt        0.0\n",
       "SynAck        0.0\n",
       "AckDat        0.0\n",
       "Offset        0.0\n",
       "sMeanPktSz    0.0\n",
       "dMeanPktSz    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_radiflow_attack_df.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fundamental-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_radiflow_attack_df[\"StartTime\"] = data_radiflow_attack_df[\"StartTime\"].apply(lambda x : createTimestamp(\"23-06-2021 \" + x.split(\".c\")[1].strip()))\n",
    "data_radiflow_attack_df[\"LastTime\"] = data_radiflow_attack_df[\"LastTime\"].apply(lambda x : createTimestamp(\"23-06-2021 \" + x.split(\".c\")[1].strip()))\n",
    "data_radiflow_attack_df[\"SrcAddr\"] = data_radiflow_attack_df[\"SrcAddr\"].apply(lambda x : convertToNum(\"ips\", x, unique_vals))\n",
    "data_radiflow_attack_df[\"DstAddr\"] = data_radiflow_attack_df[\"DstAddr\"].apply(lambda x : convertToNum(\"ips\", x, unique_vals))\n",
    "data_radiflow_attack_df[\"Sport\"] = data_radiflow_attack_df[\"Sport\"].apply(lambda x : convertPortToNum(x))\n",
    "data_radiflow_attack_df[\"Dport\"] = data_radiflow_attack_df[\"Dport\"].apply(lambda x : convertPortToNum(x))\n",
    "\n",
    "data_radiflow_attack_rowless[\"StartTime\"] = data_radiflow_attack_rowless[\"StartTime\"].apply(lambda x : createTimestamp(\"23-06-2021 \" + x.split(\".c\")[1].strip()))\n",
    "data_radiflow_attack_rowless[\"LastTime\"] = data_radiflow_attack_rowless[\"LastTime\"].apply(lambda x : createTimestamp(\"23-06-2021 \" + x.split(\".c\")[1].strip()))\n",
    "data_radiflow_attack_rowless[\"SrcAddr\"] = data_radiflow_attack_rowless[\"SrcAddr\"].apply(lambda x : convertToNum(\"ips\", x, unique_vals))\n",
    "data_radiflow_attack_rowless[\"DstAddr\"] = data_radiflow_attack_rowless[\"DstAddr\"].apply(lambda x : convertToNum(\"ips\", x, unique_vals))\n",
    "data_radiflow_attack_rowless[\"Sport\"] = data_radiflow_attack_rowless[\"Sport\"].apply(lambda x : convertPortToNum(x))\n",
    "data_radiflow_attack_rowless[\"Dport\"] = data_radiflow_attack_rowless[\"Dport\"].apply(lambda x : convertPortToNum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "identified-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_radiflow_attack_df[\"Dir\"] = data_radiflow_attack_df[\"Dir\"].apply(lambda x : convertToNum(\"dir\", x, unique_vals))\n",
    "data_radiflow_attack_rowless[\"Dir\"] = data_radiflow_attack_rowless[\"Dir\"].apply(lambda x : convertToNum(\"dir\", x, unique_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "collect-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_radiflow_attack_df[\"Classification\"] = 0\n",
    "data_radiflow_attack_rowless[\"Classification\"] = 0\n",
    "\n",
    "data_radiflow_normal_df[\"Classification\"] = 0\n",
    "data_radiflow_normal_rowless[\"Classification\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "analyzed-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_attack = (data_radiflow_attack_df[\"StartTime\"] >= createTimestamp(\"23-06-2021 12:45:00.00\")) & (data_radiflow_attack_df[\"StartTime\"] < createTimestamp(\"23-06-2021 12:52:00.00\"))\n",
    "data_radiflow_attack_df.loc[first_attack, \"Classification\"] = 1\n",
    "\n",
    "second_attack = (data_radiflow_attack_df[\"StartTime\"] >= createTimestamp(\"23-06-2021 12:56:00.00\")) & (data_radiflow_attack_df[\"StartTime\"] < createTimestamp(\"23-06-2021 13:02:00.00\"))\n",
    "data_radiflow_attack_df.loc[second_attack, \"Classification\"] = 2\n",
    "\n",
    "third_attack = (data_radiflow_attack_df[\"StartTime\"] >= createTimestamp(\"23-06-2021 13:06:00.00\")) & (data_radiflow_attack_df[\"StartTime\"] < createTimestamp(\"23-06-2021 13:12:00.00\"))\n",
    "data_radiflow_attack_df.loc[third_attack, \"Classification\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "greenhouse-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_attack = (data_radiflow_attack_rowless[\"StartTime\"] >= createTimestamp(\"23-06-2021 12:45:00.00\")) & (data_radiflow_attack_rowless[\"StartTime\"] < createTimestamp(\"23-06-2021 12:52:00.00\"))\n",
    "data_radiflow_attack_rowless.loc[first_attack, \"Classification\"] = 1\n",
    "\n",
    "second_attack = (data_radiflow_attack_rowless[\"StartTime\"] >= createTimestamp(\"23-06-2021 12:56:00.00\")) & (data_radiflow_attack_rowless[\"StartTime\"] < createTimestamp(\"23-06-2021 13:02:00.00\"))\n",
    "data_radiflow_attack_rowless.loc[second_attack, \"Classification\"] = 2\n",
    "\n",
    "third_attack = (data_radiflow_attack_rowless[\"StartTime\"] >= createTimestamp(\"23-06-2021 13:06:00.00\")) & (data_radiflow_attack_rowless[\"StartTime\"] < createTimestamp(\"23-06-2021 13:12:00.00\"))\n",
    "data_radiflow_attack_rowless.loc[third_attack, \"Classification\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "noble-equity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40980, 40)\n",
      "(33062, 44)\n"
     ]
    }
   ],
   "source": [
    "data_full_df = pd.concat([data_radiflow_normal_df, data_radiflow_attack_df], ignore_index=True, sort=False)\n",
    "data_full_rowless = pd.concat([data_radiflow_normal_rowless, data_radiflow_attack_rowless], ignore_index=True, sort=False)\n",
    "\n",
    "print(data_full_df.shape)\n",
    "print(data_full_rowless.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "worse-anger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', '*', '* d', '* *', '* s', '*  S', '* g', '* dD', '* *D', '*  D', '*U']\n",
      "['e', '*', 'd', 's', 'S', 'g', 'D', 'U', '*2']\n"
     ]
    }
   ],
   "source": [
    "unique_flags = []\n",
    "def add_unique(flags_str):\n",
    "    if flags_str not in unique_flags:\n",
    "        unique_flags.append(flags_str)\n",
    "        return flags_str\n",
    "    \n",
    "individual_flags = []\n",
    "def extractIndividualFlags(unique_flags):\n",
    "    for flag_str in unique_flags:\n",
    "        flag_list = flag_str.split(\" \")\n",
    "        for flag in flag_list:\n",
    "            if (flag != \"\") and (flag not in individual_flags):\n",
    "                individual_flags.extend([char for char in flag if char not in individual_flags])\n",
    "                \n",
    "data_full_df[\"Flgs\"].apply(lambda x : add_unique(x.strip()))\n",
    "print(unique_flags)\n",
    "extractIndividualFlags(unique_flags)\n",
    "#Ugly but needs to be done manually. This is also a possible unique value.\n",
    "individual_flags.append(\"*2\")\n",
    "print(individual_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "through-indian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      StartTime      LastTime        Flgs  Dur  RunTime  Mean  Sum  Min  Max  \\\n",
      "0  1.624540e+09  1.624540e+09   e          0.0      0.0   0.0  0.0  0.0  0.0   \n",
      "1  1.624540e+09  1.624540e+09   e          0.0      0.0   0.0  0.0  0.0  0.0   \n",
      "2  1.624540e+09  1.624540e+09   e          0.0      0.0   0.0  0.0  0.0  0.0   \n",
      "3  1.624540e+09  1.624540e+09   e          0.0      0.0   0.0  0.0  0.0  0.0   \n",
      "4  1.624540e+09  1.624540e+09   e          0.0      0.0   0.0  0.0  0.0  0.0   \n",
      "\n",
      "   SrcAddr  ...  Classification  Flg-e  Flg-*  Flg-d Flg-s  Flg-S  Flg-g  \\\n",
      "0        0  ...               0      0      0      0     0      0      0   \n",
      "1        1  ...               0      0      0      0     0      0      0   \n",
      "2        2  ...               0      0      0      0     0      0      0   \n",
      "3        1  ...               0      0      0      0     0      0      0   \n",
      "4        1  ...               0      0      0      0     0      0      0   \n",
      "\n",
      "   Flg-D  Flg-U  Flg-*2  \n",
      "0      0      0       0  \n",
      "1      0      0       0  \n",
      "2      0      0       0  \n",
      "3      0      0       0  \n",
      "4      0      0       0  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "def add_new_columns(df, individual_flags):\n",
    "    for flg in individual_flags:\n",
    "        df[\"Flg-\"+flg] = 0\n",
    "    return df\n",
    "\n",
    "add_new_columns(data_full_df, individual_flags)\n",
    "add_new_columns(data_full_rowless, individual_flags)\n",
    "print(data_full_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "democratic-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertFlagToNum(row, flg_str):\n",
    "    flg_str = flg_str.replace(\" \", \"\")\n",
    "    for flg_char in flg_str:\n",
    "        if flg_char != '*':\n",
    "            row[\"Flg-\" + flg_char] = 1\n",
    "        else:\n",
    "            if len(flg_str) == 1:\n",
    "                row[\"Flg-*\"] = 1\n",
    "            else:\n",
    "                if flg_str.count(\"*\") == 2:\n",
    "                    row[\"Flg-*\"] = 1\n",
    "                    row[\"Flg-*2\"] = 1\n",
    "                elif flg_str.index(\"*\") != 0:\n",
    "                    row[\"Flg-*2\"] = 1\n",
    "                elif flg_str.index(\"*\") == 0:\n",
    "                    row[\"Flg-*\"] = 1\n",
    "    return row\n",
    "                    \n",
    "data_full_df = data_full_df.apply(lambda x : convertFlagToNum(x, x.Flgs), axis=1)\n",
    "data_full_rowless = data_full_rowless.apply(lambda x : convertFlagToNum(x, x.Flgs), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "stable-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_df = data_full_df.drop([\"Flgs\"], axis=1)\n",
    "data_full_rowless = data_full_rowless.drop([\"Flgs\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "toxic-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_full = pd.get_dummies(data_full_df[\"Cause\"])\n",
    "data_full_df = data_full_df.drop([\"Cause\"], axis=1)\n",
    "data_full_df = data_full_df.join(cause_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "minus-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_full = pd.get_dummies(data_full_rowless[\"Cause\"])\n",
    "data_full_rowless = data_full_rowless.drop([\"Cause\"], axis=1)\n",
    "data_full_rowless = data_full_rowless.join(cause_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "behavioral-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_full = pd.get_dummies(data_full_df[\"State\"])\n",
    "data_full_df = data_full_df.drop([\"State\"], axis=1)\n",
    "data_full_df = data_full_df.join(state_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "another-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_full = pd.get_dummies(data_full_rowless[\"State\"])\n",
    "data_full_rowless = data_full_rowless.drop([\"State\"], axis=1)\n",
    "data_full_rowless = data_full_rowless.join(state_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "passing-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data_full_df.columns\n",
    "cols_list = list(cols)\n",
    "cols_list.remove(\"Classification\")\n",
    "cols_list.append(\"Classification\")\n",
    "data_full_df = data_full_df[cols_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "double-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data_full_rowless.columns\n",
    "cols_list = list(cols)\n",
    "cols_list.remove(\"Classification\")\n",
    "cols_list.append(\"Classification\")\n",
    "data_full_rowless = data_full_rowless[cols_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "instructional-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_df.to_csv(\"data_full_radiflow_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "final-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_rowless.to_csv(\"data_full_rowless_radiflow_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "western-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code is taken straight from: https://stackoverflow.com/questions/19201290/how-to-save-a-dictionary-to-a-file/32216025\n",
    "\"\"\"\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb+') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "super-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(unique_vals, \"unique_vals_radiflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "compliant-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "ip_dict_reversed = {}\n",
    "for ip, num in unique_vals[\"ips\"].items():\n",
    "    ip_dict_reversed[num] = ip\n",
    "\n",
    "with open('ipdict_radiflow.json', 'w+') as fp:\n",
    "    json.dump(ip_dict_reversed, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "corporate-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(data_full_df.columns)\n",
    "save_obj(features, 'radiflow_features')\n",
    "\n",
    "features_rowless = list(data_full_rowless)\n",
    "save_obj(features_rowless, 'radiflow_rowless_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "corresponding-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_arr = data_full_df.to_numpy()\n",
    "data_full_rowless_arr = data_full_rowless.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "amended-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('radiflow_datafull.npy', data_full_arr)\n",
    "np.save('radiflow_rowless.npy', data_full_rowless_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "racial-federation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>LastTime</th>\n",
       "      <th>dMeanPktSz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>1.624540e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40975</th>\n",
       "      <td>1.624454e+09</td>\n",
       "      <td>1.624454e+09</td>\n",
       "      <td>96.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40976</th>\n",
       "      <td>1.624454e+09</td>\n",
       "      <td>1.624454e+09</td>\n",
       "      <td>96.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40977</th>\n",
       "      <td>1.624454e+09</td>\n",
       "      <td>1.624454e+09</td>\n",
       "      <td>401.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40978</th>\n",
       "      <td>1.624454e+09</td>\n",
       "      <td>1.624454e+09</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40979</th>\n",
       "      <td>1.624454e+09</td>\n",
       "      <td>1.624454e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40980 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          StartTime      LastTime  dMeanPktSz\n",
       "0      1.624540e+09  1.624540e+09    0.000000\n",
       "1      1.624540e+09  1.624540e+09    0.000000\n",
       "2      1.624540e+09  1.624540e+09    0.000000\n",
       "3      1.624540e+09  1.624540e+09    0.000000\n",
       "4      1.624540e+09  1.624540e+09    0.000000\n",
       "...             ...           ...         ...\n",
       "40975  1.624454e+09  1.624454e+09   96.250000\n",
       "40976  1.624454e+09  1.624454e+09   96.250000\n",
       "40977  1.624454e+09  1.624454e+09  401.600006\n",
       "40978  1.624454e+09  1.624454e+09   66.000000\n",
       "40979  1.624454e+09  1.624454e+09    0.000000\n",
       "\n",
       "[40980 rows x 3 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_df[[\"StartTime\", \"LastTime\", \"dMeanPktSz\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
